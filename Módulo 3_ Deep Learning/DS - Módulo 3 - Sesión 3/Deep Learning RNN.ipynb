{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Deep Learning RNN.ipynb","provenance":[{"file_id":"https://github.com/tensorflow/docs/blob/snapshot-keras/site/en/guide/keras/rnn.ipynb","timestamp":1634596982516}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"b518b04cbfe0"},"source":["\n","### Data Science\n","### Módulo 3 _ Deep Learning\n","\n","\n","# Recurrent Neural Networks (RNN) with Keras\n","\n","### `Skillsforindustry.org`\n","\n","##### Copyright 2019 The TensorFlow Authors.\n"]},{"cell_type":"markdown","metadata":{"id":"6ca65cda94c8"},"source":["# Recurrent Neural Networks (RNN) with Keras"]},{"cell_type":"markdown","metadata":{"id":"6873211b02d4"},"source":["\n","##**Introducción**\n","Las redes neuronales recurrentes (RNN) son una clase de redes neuronales que es poderosa para modelar datos de secuencia, como series de tiempo o lenguaje natural.\n","\n","De manera esquemática, una capa RNN usa un bucle for para iterar sobre los pasos de tiempo de una secuencia, mientras mantiene un estado interno que codifica información sobre los pasos de tiempo que ha visto hasta ahora.\n","\n","La API de Keras RNN está diseñada con un enfoque en:\n","\n","**Facilidad de uso:** las capas integradas keras.layers.RNN, keras.layers.LSTM, keras.layers.GRU le permiten crear rápidamente modelos recurrentes sin tener que hacer elecciones de configuración difíciles.\n","\n","**Facilidad de personalización:** también puede definir su propia capa de celda RNN (la parte interna del bucle for) con un comportamiento personalizado y utilizarla con la capa genérica keras.layers.RNN (el bucle for en sí). Esto le permite crear rápidamente prototipos de diferentes ideas de investigación de una manera flexible con un código mínimo."]},{"cell_type":"markdown","metadata":{"id":"PGhaqiKvn2Sp"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"b3600ee25c8e"},"source":["## Setup"]},{"cell_type":"code","metadata":{"id":"71c626bbac35"},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4041a2e9b310"},"source":["## Built-in RNN layers: a simple example"]},{"cell_type":"markdown","metadata":{"id":"98e0c38cf95d"},"source":["Existent 3 built-in RNN layers en Keras:\n","\n","1. `keras.layers.SimpleRNN`,un RNN completamente conectado donde la salida del paso de tiempo anterior debe alimentarse al siguiente paso de tiempo.\n","\n","2. `keras.layers.GRU`, propuesto por primera vez en:\n","[Cho et al., 2014](https://arxiv.org/abs/1406.1078).\n","\n","3. `keras.layers.LSTM`, propuesto por primera vez en:\n","[Hochreiter & Schmidhuber, 1997](https://www.bioinf.jku.at/publications/older/2604.pdf).\n","\n","A principios de 2015, Keras tuvo las primeras implementaciones de Python de código abierto reutilizables de LSTM\n","y GRU.\n","\n","A continuación, se muestra un ejemplo simple de un modelo \"secuencial\" que procesa secuencias de números enteros,\n","incrusta cada entero en un vector de 64 dimensiones, luego procesa la secuencia de\n","vectores usando una capa `LSTM`."]},{"cell_type":"code","metadata":{"id":"a5617759e54e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600014909,"user_tz":300,"elapsed":840,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"e37d36d8-6178-4f0b-c0fe-0db88b13a1bd"},"source":["model = keras.Sequential()\n","# Add an Embedding layer expecting input vocab of size 1000, and\n","# output embedding dimension of size 64.\n","model.add(layers.Embedding(input_dim=1000, output_dim=64))\n","\n","# Add a LSTM layer with 128 internal units.\n","model.add(layers.LSTM(128))\n","\n","# Add a Dense layer with 10 units.\n","model.add(layers.Dense(10))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (None, None, 64)          64000     \n","_________________________________________________________________\n","lstm (LSTM)                  (None, 128)               98816     \n","_________________________________________________________________\n","dense (Dense)                (None, 10)                1290      \n","=================================================================\n","Total params: 164,106\n","Trainable params: 164,106\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"cb8ef33660a0"},"source":["Built-in RNNs support a number of useful features:\n","\n","- Abandono recurrente, a través de los argumentos `dropout` y` recurrent_dropout`\n","- Capacidad para procesar una secuencia de entrada a la inversa, a través del argumento `go_backwards`\n","- Desenrollado de bucle (que puede conducir a una gran aceleración al procesar secuencias cortas en\n","CPU), a través del argumento `desenrollar`\n","- ...y más.\n","\n","For more information, see the\n","[RNN API documentation](https://keras.io/api/layers/recurrent_layers/)."]},{"cell_type":"markdown","metadata":{"id":"43aa4e4f344d"},"source":["\n","\n","## Outputs y estados\n","De forma predeterminada, la salida de una capa RNN contiene un solo vector por muestra. Este vector\n","es la salida de la celda RNN correspondiente al último paso de tiempo, que contiene información\n","sobre toda la secuencia de entrada. La forma de esta salida es `(batch_size, units)`\n","donde `unidades` corresponde al argumento` unidades` pasado al constructor de la capa.\n","\n","Una capa RNN también puede devolver la secuencia completa de salidas para cada muestra (un vector\n","por paso de tiempo por muestra), si establece `return_sequences = True`. La forma de esta salida\n","es `(tamaño_lote, pasos de tiempo, unidades)`."]},{"cell_type":"code","metadata":{"id":"c3294dec91e4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600018533,"user_tz":300,"elapsed":462,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"499dae10-bf07-4d9f-bd20-035b0b10a2e5"},"source":["model = keras.Sequential()\n","model.add(layers.Embedding(input_dim=1000, output_dim=64))\n","\n","# The output of GRU will be a 3D tensor of shape (batch_size, timesteps, 256)\n","model.add(layers.GRU(256, return_sequences=True))\n","\n","# The output of SimpleRNN will be a 2D tensor of shape (batch_size, 128)\n","model.add(layers.SimpleRNN(128))\n","\n","model.add(layers.Dense(10))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_1 (Embedding)      (None, None, 64)          64000     \n","_________________________________________________________________\n","gru (GRU)                    (None, None, 256)         247296    \n","_________________________________________________________________\n","simple_rnn (SimpleRNN)       (None, 128)               49280     \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 10)                1290      \n","=================================================================\n","Total params: 361,866\n","Trainable params: 361,866\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"266812a04bb2"},"source":["Además, una capa RNN puede devolver sus estados internos finales. Los estados devueltos se pueden utilizar para reanudar la ejecución de RNN más tarde o para inicializar otro RNN. Esta configuración se usa comúnmente en el modelo de secuencia a secuencia del codificador-decodificador, donde el estado final del codificador se usa como el estado inicial del decodificador.\n","\n","Para configurar una capa RNN para que devuelva su estado interno, establezca el parámetro return_state en True al crear la capa. Tenga en cuenta que LSTM tiene 2 tensores de estado, pero GRU solo tiene uno.\n","\n","Para configurar el estado inicial de la capa, simplemente llame a la capa con el argumento de palabra clave adicional initial_state. Tenga en cuenta que la forma del estado debe coincidir con el tamaño de unidad de la capa, como en el ejemplo siguiente."]},{"cell_type":"code","metadata":{"id":"ece412e6afbe","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600022906,"user_tz":300,"elapsed":874,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"aefc5f6c-d137-4ec2-fd3e-8ea69eecd5ab"},"source":["encoder_vocab = 1000\n","decoder_vocab = 2000\n","\n","encoder_input = layers.Input(shape=(None,))\n","encoder_embedded = layers.Embedding(input_dim=encoder_vocab, output_dim=64)(\n","    encoder_input\n",")\n","\n","# Return states in addition to output\n","output, state_h, state_c = layers.LSTM(64, return_state=True, name=\"encoder\")(\n","    encoder_embedded\n",")\n","encoder_state = [state_h, state_c]\n","\n","decoder_input = layers.Input(shape=(None,))\n","decoder_embedded = layers.Embedding(input_dim=decoder_vocab, output_dim=64)(\n","    decoder_input\n",")\n","\n","# Pass the 2 states to a new LSTM layer, as initial state\n","decoder_output = layers.LSTM(64, name=\"decoder\")(\n","    decoder_embedded, initial_state=encoder_state\n",")\n","output = layers.Dense(10)(decoder_output)\n","\n","model = keras.Model([encoder_input, decoder_input], output)\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            [(None, None)]       0                                            \n","__________________________________________________________________________________________________\n","embedding_2 (Embedding)         (None, None, 64)     64000       input_1[0][0]                    \n","__________________________________________________________________________________________________\n","embedding_3 (Embedding)         (None, None, 64)     128000      input_2[0][0]                    \n","__________________________________________________________________________________________________\n","encoder (LSTM)                  [(None, 64), (None,  33024       embedding_2[0][0]                \n","__________________________________________________________________________________________________\n","decoder (LSTM)                  (None, 64)           33024       embedding_3[0][0]                \n","                                                                 encoder[0][1]                    \n","                                                                 encoder[0][2]                    \n","__________________________________________________________________________________________________\n","dense_2 (Dense)                 (None, 10)           650         decoder[0][0]                    \n","==================================================================================================\n","Total params: 258,698\n","Trainable params: 258,698\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"e97a845a372a"},"source":["## RNN layers and RNN cells\n","\n","Además de las capas RNN integradas, la API RNN también proporciona API a nivel de celda.\n","A diferencia de las capas RNN, que procesan lotes completos de secuencias de entrada, la celda RNN solo\n","procesa un solo paso de tiempo.\n","\n","La celda es el interior del bucle \"for\" de una capa RNN. Envolviendo una celda dentro de un\n","La capa `keras.layers.RNN` le proporciona una capa capaz de procesar lotes de\n","secuencias, p. ej. `RNN (LSTMCell (10))`.\n","\n","Matemáticamente, `RNN (LSTMCell (10))` produce el mismo resultado que `LSTM (10)`. De hecho,\n","la implementación de esta capa en TF v1.x solo estaba creando el RNN correspondiente\n","celda y envolviéndola en una capa RNN. Sin embargo, usando el \"GRU\" incorporado y el \"LSTM\"\n","Las capas permiten el uso de CuDNN y es posible que vea un mejor rendimiento.\n","\n","Hay tres celdas RNN integradas, cada una de las cuales corresponde al RNN correspondiente.\n","capa.\n","\n","- `keras.layers.SimpleRNNCell` corresponds to the `SimpleRNN` layer.\n","\n","- `keras.layers.GRUCell` corresponds to the `GRU` layer.\n","\n","- `keras.layers.LSTMCell` corresponds to the `LSTM` layer.\n","\n","La abstracción de la celda, junto con la clase genérica `keras.layers.RNN`, la hacen\n","muy fácil de implementar arquitecturas RNN personalizadas para su investigación."]},{"cell_type":"markdown","metadata":{"id":"60b3b721d500"},"source":["## Cross-batch statefulness\n","\n","Al procesar secuencias muy largas (posiblemente infinitas), es posible que desee utilizar la\n","patrón de ** estado de lotes cruzados **.\n","\n","Normalmente, el estado interno de una capa RNN se restablece cada vez que ve un nuevo lote\n","(es decir, se supone que cada muestra vista por la capa es independiente del pasado). los\n","La capa solo mantendrá un estado mientras procesa una muestra determinada.\n","\n","Sin embargo, si tiene secuencias muy largas, es útil dividirlas en\n","secuencias, y para alimentar estas secuencias más cortas secuencialmente en una capa RNN sin\n","restableciendo el estado de la capa. De esa forma, la capa puede retener información sobre el\n","la totalidad de la secuencia, aunque solo vea una subsecuencia a la vez.\n","\n","Puede hacer esto configurando `stateful = True` en el constructor.\n","\n","Si tiene una secuencia `s = [t0, t1, ... t1546, t1547]`, la dividiría en p. Ej.\n","\n","```\n","s1 = [t0, t1, ... t100]\n","s2 = [t101, ... t201]\n","...\n","s16 = [t1501, ... t1547]\n","```\n","\n","Then you would process it via:\n","\n","```python\n","lstm_layer = layers.LSTM(64, stateful=True)\n","for s in sub_sequences:\n","  output = lstm_layer(s)\n","```\n","\n","When you want to clear the state, you  can use `layer.reset_states()`.\n","\n","\n","> Nota: En esta configuración, se supone que la muestra `i` en un lote dado es la continuación de\n","muestra `i` en el lote anterior. Esto significa que todos los lotes deben contener el mismo\n","número de muestras (tamaño del lote). P.ej. si un lote contiene `[secuencia_A_desde_t0_to_t100,\n","  sequence_B_from_t0_to_t100] `, el siguiente lote debe contener\n","`[secuencia_A_desde_t101_ha_t200, secuencia_B_desde_t101_to_t200]`.\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"19e72be49a42"},"source":["paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n","paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n","paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n","\n","lstm_layer = layers.LSTM(64, stateful=True)\n","output = lstm_layer(paragraph1)\n","output = lstm_layer(paragraph2)\n","output = lstm_layer(paragraph3)\n","\n","# reset_states() will reset the cached state to the original initial_state.\n","# If no initial_state was provided, zero-states will be used by default.\n","lstm_layer.reset_states()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ec7c316b19a1"},"source":["### RNN Reuso de Estado\n","<a id=\"rnn_state_reuse\"></a>"]},{"cell_type":"markdown","metadata":{"id":"3cb7a8ac464a"},"source":["Los estados registrados de la capa RNN no se incluyen en el `layer.weights ()`. Si tu\n","desea reutilizar el estado de una capa RNN, puede recuperar el valor de los estados mediante\n","`layer.states` y utilícelo como\n","estado inicial para una nueva capa a través de la API funcional de Keras como `new_layer (entradas,\n","initial_state = layer.states) `, o subclases del modelo.\n","\n","Tenga en cuenta también que es posible que el modelo secuencial no se utilice en este caso, ya que solo\n","admite capas con una sola entrada y salida, la entrada adicional del estado inicial hace\n","es imposible de usar aquí."]},{"cell_type":"code","metadata":{"id":"009c5b393adf"},"source":["paragraph1 = np.random.random((20, 10, 50)).astype(np.float32)\n","paragraph2 = np.random.random((20, 10, 50)).astype(np.float32)\n","paragraph3 = np.random.random((20, 10, 50)).astype(np.float32)\n","\n","lstm_layer = layers.LSTM(64, stateful=True)\n","output = lstm_layer(paragraph1)\n","output = lstm_layer(paragraph2)\n","\n","existing_state = lstm_layer.states\n","\n","new_lstm_layer = layers.LSTM(64)\n","new_output = new_lstm_layer(paragraph3, initial_state=existing_state)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"66c1d7f1ccba"},"source":["## Bidirectional RNNs\n","\n","Para secuencias que no sean series de tiempo (por ejemplo, texto), a menudo ocurre que un modelo RNN\n","puede funcionar mejor si no solo procesa la secuencia de principio a fin, sino también\n","hacia atrás. Por ejemplo, para predecir la siguiente palabra en una oración, a menudo es útil\n","tenga el contexto alrededor de la palabra, no solo las palabras que le preceden.\n","\n","Keras proporciona una API fácil para que usted cree tales RNN bidireccionales: el\n","Envoltorio `keras.layers.Bidirectional`."]},{"cell_type":"code","metadata":{"id":"8cea1781a0c2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600037629,"user_tz":300,"elapsed":1354,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"ec777803-581a-4963-9180-2632a227b736"},"source":["model = keras.Sequential()\n","\n","model.add(\n","    layers.Bidirectional(layers.LSTM(64, return_sequences=True), input_shape=(5, 10))\n",")\n","model.add(layers.Bidirectional(layers.LSTM(32)))\n","model.add(layers.Dense(10))\n","\n","model.summary()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional (Bidirectional (None, 5, 128)            38400     \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 64)                41216     \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 10)                650       \n","=================================================================\n","Total params: 80,266\n","Trainable params: 80,266\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"dab57c97a566"},"source":["`Bidirectional` copiará la capa RNN pasada y volteará el\n","campo `go_backwards` de la capa recién copiada, para que procese las entradas en\n","orden inverso.\n","\n","La salida del RNN \"Bidireccional\" será, por defecto, la concatenación de la capa directa.\n","salida y la salida de la capa hacia atrás. Si necesita un comportamiento de fusión diferente, p. Ej.\n","concatenación, cambie el parámetro `merge_mode` en el contenedor` Bidirectional`\n","constructor."]},{"cell_type":"markdown","metadata":{"id":"18a254dfaa73"},"source":["## Performance optimization and CuDNN kernels\n","\n","En TensorFlow 2.0, las capas integradas LSTM y GRU se actualizaron para aprovechar CuDNN\n","kernels de forma predeterminada cuando hay una GPU disponible. Con este cambio, el anterior\n","Las capas `keras.layers.CuDNNLSTM / CuDNNGRU` han quedado obsoletas y puede crear sus\n","modelo sin preocuparse por el hardware en el que se ejecutará.\n","\n","Dado que el kernel CuDNN está construido con ciertas suposiciones, esto significa que la capa **\n","no podrá utilizar el kernel CuDNN si cambia los valores predeterminados del LSTM incorporado o\n","Capas GRU **. P.ej.:\n","\n","- Cambiar la función de `activación` de` tanh` a otra cosa.\n","- Cambiar la función `recurrent_activation` de` sigmoid` a otra cosa.\n","- Usando `recurrent_dropout`> 0.\n","- Establecer `desenrollar` en Verdadero, lo que obliga a LSTM / GRU a descomponer el interior\n","`tf. while_loop` en un bucle` for` desenrollado.\n","- Establecer `use_bias` en False.\n","- Usar enmascaramiento cuando los datos de entrada no están estrictamente rellenados a la derecha (si la máscara\n","corresponde a datos rellenados estrictamente a la derecha, CuDNN todavía se puede utilizar. Esto es lo más\n","caso común).\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fb8de09c4343"},"source":["### Using CuDNN kernels when available\n","\n","Construyamos un modelo LSTM simple para demostrar la diferencia de rendimiento.\n","\n","Usaremos como secuencias de entrada la secuencia de filas de dígitos MNIST (tratando cada fila de\n","píxeles como un paso de tiempo), y predeciremos la etiqueta del dígito."]},{"cell_type":"code","metadata":{"id":"e88aab9e73c7"},"source":["batch_size = 64\n","# Each MNIST image batch is a tensor of shape (batch_size, 28, 28).\n","# Each input sequence will be of size (28, 28) (height is treated like time).\n","input_dim = 28\n","\n","units = 64\n","output_size = 10  # labels are from 0 to 9\n","\n","# Build the RNN model\n","def build_model(allow_cudnn_kernel=True):\n","    # CuDNN is only available at the layer level, and not at the cell level.\n","    # This means `LSTM(units)` will use the CuDNN kernel,\n","    # while RNN(LSTMCell(units)) will run on non-CuDNN kernel.\n","    if allow_cudnn_kernel:\n","        # The LSTM layer with default options uses CuDNN.\n","        lstm_layer = keras.layers.LSTM(units, input_shape=(None, input_dim))\n","    else:\n","        # Wrapping a LSTMCell in a RNN layer will not use CuDNN.\n","        lstm_layer = keras.layers.RNN(\n","            keras.layers.LSTMCell(units), input_shape=(None, input_dim)\n","        )\n","    model = keras.models.Sequential(\n","        [\n","            lstm_layer,\n","            keras.layers.BatchNormalization(),\n","            keras.layers.Dense(output_size),\n","        ]\n","    )\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dcde82cb14d6"},"source":["Let's load the MNIST dataset:"]},{"cell_type":"code","metadata":{"id":"98292f8e71a9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600045855,"user_tz":300,"elapsed":1137,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"8ae854d7-64fd-41be-eed1-31c6bfb0ab15"},"source":["mnist = keras.datasets.mnist\n","\n","(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train, x_test = x_train / 255.0, x_test / 255.0\n","sample, sample_label = x_train[0], y_train[0]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11493376/11490434 [==============================] - 0s 0us/step\n","11501568/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"443e5458284f"},"source":["Creemos una instancia de modelo y entreneémosla.\n","\n","Elegimos `sparse_categorical_crossentropy` como la función de pérdida para el modelo. los\n","la salida del modelo tiene la forma de \"[batch_size, 10]\". El objetivo del modelo es un\n","vector entero, cada uno de los números enteros está en el rango de 0 a 9."]},{"cell_type":"code","metadata":{"id":"f85b57b010e5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600091201,"user_tz":300,"elapsed":43827,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"61a3adaa-88d0-4e01-d7bb-86ae10931afa"},"source":["model = build_model(allow_cudnn_kernel=True)\n","\n","model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=\"sgd\",\n","    metrics=[\"accuracy\"],\n",")\n","\n","\n","model.fit(\n","    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["938/938 [==============================] - 25s 24ms/step - loss: 0.9702 - accuracy: 0.6945 - val_loss: 0.5324 - val_accuracy: 0.8380\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc9fdbe8c50>"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"99ea5495e375"},"source":["Ahora, comparemos con un modelo que no usa el kernel CuDNN:"]},{"cell_type":"code","metadata":{"id":"d4bdff02e617","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1634600134385,"user_tz":300,"elapsed":42657,"user":{"displayName":"Skills For Industry","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Ghk3twFc26-WI03YT5H9fVJrFROQ74QFzR8DkZX=s64","userId":"07503178445500768852"}},"outputId":"581fa0f7-eee6-41a0-af82-6258ca6d15f8"},"source":["noncudnn_model = build_model(allow_cudnn_kernel=False)\n","noncudnn_model.set_weights(model.get_weights())\n","noncudnn_model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=\"sgd\",\n","    metrics=[\"accuracy\"],\n",")\n","noncudnn_model.fit(\n","    x_train, y_train, validation_data=(x_test, y_test), batch_size=batch_size, epochs=1\n",")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["938/938 [==============================] - 24s 24ms/step - loss: 0.4066 - accuracy: 0.8770 - val_loss: 0.3180 - val_accuracy: 0.9033\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7fc9fdb8ac10>"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"90fc64fbd4ea"},"source":["Cuando se ejecuta en una máquina con una GPU NVIDIA y CuDNN instalados,\n","el modelo construido con CuDNN es mucho más rápido de entrenar en comparación con el\n","modelo que usa el kernel regular de TensorFlow.\n","\n","El mismo modelo habilitado para CuDNN también se puede utilizar para ejecutar inferencias en una CPU\n","medio ambiente. La anotación `tf.device` a continuación solo está forzando la ubicación del dispositivo.\n","El modelo se ejecutará en la CPU de forma predeterminada si no hay GPU disponible.\n","\n","Simplemente ya no tiene que preocuparse por el hardware en el que está ejecutando. "]},{"cell_type":"code","metadata":{"id":"7e33c62b6029"},"source":["import matplotlib.pyplot as plt\n","\n","with tf.device(\"CPU:0\"):\n","    cpu_model = build_model(allow_cudnn_kernel=True)\n","    cpu_model.set_weights(model.get_weights())\n","    result = tf.argmax(cpu_model.predict_on_batch(tf.expand_dims(sample, 0)), axis=1)\n","    print(\n","        \"Predicted result is: %s, target result is: %s\" % (result.numpy(), sample_label)\n","    )\n","    plt.imshow(sample, cmap=plt.get_cmap(\"gray\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2f940b73a2a6"},"source":["## RNNs with list/dict inputs, or nested inputs\n","\n","Las estructuras anidadas permiten a los implementadores incluir más información en un solo\n","hora de caminar. Por ejemplo, un cuadro de video podría tener entrada de audio y video al mismo\n","tiempo. La forma de los datos en este caso podría ser:\n","\n","`[lote, intervalo de tiempo, {\" video \": [altura, ancho, canal],\" audio \": [frecuencia]}]`\n","\n","En otro ejemplo, los datos de escritura a mano podrían tener ambas coordenadas xey para la\n","posición actual del lápiz, así como información sobre la presión. Entonces los datos\n","la representación podría ser:\n","\n","`[lote, intervalo de tiempo, {\" ubicación \": [x, y],\" presión \": [fuerza]}]`\n","\n","El siguiente código proporciona un ejemplo de cómo construir una celda RNN personalizada que acepta\n","tales insumos estructurados."]},{"cell_type":"markdown","metadata":{"id":"f78dc4c1c516"},"source":["### Define a custom cell that supports nested input/output"]},{"cell_type":"markdown","metadata":{"id":"199faf57f0c5"},"source":[""]},{"cell_type":"code","metadata":{"id":"451cfd5f0cc4"},"source":["class NestedCell(keras.layers.Layer):\n","    def __init__(self, unit_1, unit_2, unit_3, **kwargs):\n","        self.unit_1 = unit_1\n","        self.unit_2 = unit_2\n","        self.unit_3 = unit_3\n","        self.state_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n","        self.output_size = [tf.TensorShape([unit_1]), tf.TensorShape([unit_2, unit_3])]\n","        super(NestedCell, self).__init__(**kwargs)\n","\n","    def build(self, input_shapes):\n","        # expect input_shape to contain 2 items, [(batch, i1), (batch, i2, i3)]\n","        i1 = input_shapes[0][1]\n","        i2 = input_shapes[1][1]\n","        i3 = input_shapes[1][2]\n","\n","        self.kernel_1 = self.add_weight(\n","            shape=(i1, self.unit_1), initializer=\"uniform\", name=\"kernel_1\"\n","        )\n","        self.kernel_2_3 = self.add_weight(\n","            shape=(i2, i3, self.unit_2, self.unit_3),\n","            initializer=\"uniform\",\n","            name=\"kernel_2_3\",\n","        )\n","\n","    def call(self, inputs, states):\n","        # inputs should be in [(batch, input_1), (batch, input_2, input_3)]\n","        # state should be in shape [(batch, unit_1), (batch, unit_2, unit_3)]\n","        input_1, input_2 = tf.nest.flatten(inputs)\n","        s1, s2 = states\n","\n","        output_1 = tf.matmul(input_1, self.kernel_1)\n","        output_2_3 = tf.einsum(\"bij,ijkl->bkl\", input_2, self.kernel_2_3)\n","        state_1 = s1 + output_1\n","        state_2_3 = s2 + output_2_3\n","\n","        output = (output_1, output_2_3)\n","        new_states = (state_1, state_2_3)\n","\n","        return output, new_states\n","\n","    def get_config(self):\n","        return {\"unit_1\": self.unit_1, \"unit_2\": unit_2, \"unit_3\": self.unit_3}\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"51355b4089d2"},"source":["### Build a RNN model with nested input/output\n","\n","Construyamos un modelo de Keras que use una capa `keras.layers.RNN` y la celda personalizada\n","acabamos de definir."]},{"cell_type":"code","metadata":{"id":"b2eba7a248eb"},"source":["unit_1 = 10\n","unit_2 = 20\n","unit_3 = 30\n","\n","i1 = 32\n","i2 = 64\n","i3 = 32\n","batch_size = 64\n","num_batches = 10\n","timestep = 50\n","\n","cell = NestedCell(unit_1, unit_2, unit_3)\n","rnn = keras.layers.RNN(cell)\n","\n","input_1 = keras.Input((None, i1))\n","input_2 = keras.Input((None, i2, i3))\n","\n","outputs = rnn((input_1, input_2))\n","\n","model = keras.models.Model([input_1, input_2], outputs)\n","\n","model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"452a99c63b7c"},"source":["### Train the model with randomly generated data\n","\n","Dado que no hay un buen conjunto de datos candidato para este modelo, utilizamos datos aleatorios de Numpy para\n","demostración."]},{"cell_type":"code","metadata":{"id":"3987993cb7be"},"source":["input_1_data = np.random.random((batch_size * num_batches, timestep, i1))\n","input_2_data = np.random.random((batch_size * num_batches, timestep, i2, i3))\n","target_1_data = np.random.random((batch_size * num_batches, unit_1))\n","target_2_data = np.random.random((batch_size * num_batches, unit_2, unit_3))\n","input_data = [input_1_data, input_2_data]\n","target_data = [target_1_data, target_2_data]\n","\n","model.fit(input_data, target_data, batch_size=batch_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b51e87780b0f"},"source":["Con la capa Keras `keras.layers.RNN`, solo se espera que defina las matemáticas\n","lógica para el paso individual dentro de la secuencia, y la capa `keras.layers.RNN`\n","se encargará de la iteración de la secuencia por usted. Es una forma increíblemente poderosa de\n","prototipo de nuevos tipos de RNN (por ejemplo, una variante de LSTM).\n","\n","Para más información[API docs](https://https://www.tensorflow.org/api_docs/python/tf/keras/layers/RNN/)."]}]}